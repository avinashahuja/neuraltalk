----------------------------------------
Begin Torque Prologue on nid25348
at Fri Nov 25 21:08:56 CST 2016
Job Id:			5800582.bw
Username:		tra245
Group:			TRAIN_bacu
Job name:		neruraltalk_16cores
Requested resources:	neednodes=1:ppn=16:xk,nodes=1:ppn=16:xk,walltime=40:00:00
Queue:			normal
Account:		bacu
End Torque Prologue:  0.070 elapsed
----------------------------------------




parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.34s
0/20 batch done in 4.387s. at epoch 0.00. loss cost = 279.923645, 
0/20 batch done in 4.389s. at epoch 0.00. loss cost = 297.033234, 
0/20 batch done in 4.405s. at epoch 0.00. loss cost = 288.924927, 
0/20 batch done in 4.421s. at epoch 0.00. loss cost = 285.313873, 
0/20 batch done in 4.434s. at epoch 0.00. loss cost = 286.881897, 
0/20 batch done in 4.437s. at epoch 0.00. loss cost = 290.110107, 
0/20 batch done in 4.427s. at epoch 0.00. loss cost = 290.141479, 
0/20 batch done in 4.427s. at epoch 0.00. loss cost = 274.778717, 
0/20 batch done in 4.426s. at epoch 0.00. loss cost = 291.517822, 
0/20 batch done in 4.431s. at epoch 0.00. loss cost = 290.161285, 
0/20 batch done in 4.433s. at epoch 0.00. loss cost = 280.139557, 
0/20 batch done in 4.433s. at epoch 0.00. loss cost = 279.768768, 
0/20 batch done in 4.435s. at epoch 0.00. loss cost = 297.027435, 
0/20 batch done in 4.435s. at epoch 0.00. loss cost = 298.539215, 
0/20 batch done in 4.436s. at epoch 0.00. loss cost = 283.705261, 
0/20 batch done in 4.436s. at epoch 0.00. loss cost = 283.553223, 
1/20 batch done in 3.723s. at epoch 0.00. loss cost = 269.714844, 
1/20 batch done in 3.742s. at epoch 0.00. loss cost = 270.992767, 
1/20 batch done in 4.065s. at epoch 0.00. loss cost = 277.911194, 
1/20 batch done in 4.067s. at epoch 0.00. loss cost = 258.118103, 
1/20 batch done in 4.041s. at epoch 0.00. loss cost = 261.586609, 
1/20 batch done in 4.041s. at epoch 0.00. loss cost = 263.896179, 
1/20 batch done in 4.053s. at epoch 0.00. loss cost = 276.259094, 
1/20 batch done in 4.053s. at epoch 0.00. loss cost = 272.967224, 
1/20 batch done in 4.056s. at epoch 0.00. loss cost = 265.363342, 
1/20 batch done in 4.056s. at epoch 0.00. loss cost = 264.188171, 
1/20 batch done in 4.106s. at epoch 0.00. loss cost = 272.516602, 
1/20 batch done in 4.106s. at epoch 0.00. loss cost = 259.327393, 
1/20 batch done in 4.109s. at epoch 0.00. loss cost = 267.369720, 
1/20 batch done in 4.109s. at epoch 0.00. loss cost = 257.922516, 
1/20 batch done in 4.109s. at epoch 0.00. loss cost = 270.644348, 
1/20 batch done in 4.109s. at epoch 0.00. loss cost = 267.246613, 
2/20 batch done in 2.658s. at epoch 0.01. loss cost = 239.619827, 
2/20 batch done in 3.732s. at epoch 0.01. loss cost = 239.600113, 
2/20 batch done in 3.762s. at epoch 0.01. loss cost = 243.614288, 
2/20 batch done in 3.686s. at epoch 0.01. loss cost = 233.418976, 
2/20 batch done in 3.760s. at epoch 0.01. loss cost = 228.689972, 
2/20 batch done in 3.764s. at epoch 0.01. loss cost = 246.506378, 
2/20 batch done in 3.743s. at epoch 0.01. loss cost = 237.227066, 
2/20 batch done in 3.773s. at epoch 0.01. loss cost = 239.794403, 
2/20 batch done in 3.801s. at epoch 0.01. loss cost = 248.181808, 
2/20 batch done in 4.010s. at epoch 0.01. loss cost = 233.385300, 
2/20 batch done in 4.010s. at epoch 0.01. loss cost = 245.223770, 
2/20 batch done in 4.038s. at epoch 0.01. loss cost = 225.720932, 
2/20 batch done in 4.038s. at epoch 0.01. loss cost = 236.773468, 
2/20 batch done in 4.050s. at epoch 0.01. loss cost = 238.580978, 
2/20 batch done in 4.050s. at epoch 0.01. loss cost = 235.801758, 
3/20 batch done in 2.571s. at epoch 0.01. loss cost = 203.728928, 
3/20 batch done in 3.655s. at epoch 0.01. loss cost = 206.060394, 
3/20 batch done in 3.702s. at epoch 0.01. loss cost = 210.240952, 
3/20 batch done in 3.742s. at epoch 0.01. loss cost = 198.152542, 
3/20 batch done in 3.722s. at epoch 0.01. loss cost = 202.880600, 
3/20 batch done in 3.741s. at epoch 0.01. loss cost = 212.380768, 
3/20 batch done in 3.787s. at epoch 0.01. loss cost = 192.090714, 
3/20 batch done in 3.718s. at epoch 0.01. loss cost = 212.832550, 
3/20 batch done in 3.767s. at epoch 0.01. loss cost = 204.995316, 
4/20 batch done in 2.640s. at epoch 0.01. loss cost = 159.973175, 
3/20 batch done in 3.964s. at epoch 0.01. loss cost = 212.068298, 
3/20 batch done in 3.973s. at epoch 0.01. loss cost = 201.427353, 
3/20 batch done in 3.965s. at epoch 0.01. loss cost = 193.518921, 
3/20 batch done in 3.968s. at epoch 0.01. loss cost = 199.393250, 
3/20 batch done in 4.013s. at epoch 0.01. loss cost = 205.329300, 
3/20 batch done in 4.013s. at epoch 0.01. loss cost = 203.325348, 
5/20 batch done in 2.582s. at epoch 0.02. loss cost = 117.953705, 
4/20 batch done in 3.715s. at epoch 0.01. loss cost = 169.710251, 
4/20 batch done in 3.730s. at epoch 0.01. loss cost = 175.738876, 
4/20 batch done in 3.693s. at epoch 0.01. loss cost = 155.431885, 
4/20 batch done in 3.757s. at epoch 0.01. loss cost = 163.645020, 
4/20 batch done in 3.796s. at epoch 0.01. loss cost = 173.032303, 
4/20 batch done in 3.725s. at epoch 0.01. loss cost = 165.430832, 
4/20 batch done in 3.764s. at epoch 0.01. loss cost = 145.854324, 
4/20 batch done in 3.768s. at epoch 0.01. loss cost = 169.366699, 
4/20 batch done in 3.740s. at epoch 0.01. loss cost = 172.686691, 
4/20 batch done in 3.769s. at epoch 0.01. loss cost = 160.670578, 
4/20 batch done in 3.865s. at epoch 0.01. loss cost = 150.227570, 
4/20 batch done in 3.886s. at epoch 0.01. loss cost = 154.419876, 
4/20 batch done in 3.847s. at epoch 0.01. loss cost = 169.738007, 
4/20 batch done in 3.876s. at epoch 0.01. loss cost = 169.369339, 
6/20 batch done in 2.587s. at epoch 0.02. loss cost = 95.683823, 
5/20 batch done in 3.665s. at epoch 0.02. loss cost = 123.420341, 
5/20 batch done in 3.718s. at epoch 0.02. loss cost = 128.652008, 
5/20 batch done in 3.752s. at epoch 0.02. loss cost = 125.374481, 
5/20 batch done in 3.784s. at epoch 0.02. loss cost = 120.810020, 
5/20 batch done in 3.730s. at epoch 0.02. loss cost = 123.831032, 
5/20 batch done in 3.734s. at epoch 0.02. loss cost = 131.374863, 
5/20 batch done in 3.762s. at epoch 0.02. loss cost = 128.011902, 
5/20 batch done in 3.758s. at epoch 0.02. loss cost = 107.533768, 
5/20 batch done in 3.736s. at epoch 0.02. loss cost = 134.704590, 
5/20 batch done in 3.736s. at epoch 0.02. loss cost = 123.833191, 
7/20 batch done in 2.632s. at epoch 0.02. loss cost = 93.848648, 
5/20 batch done in 3.765s. at epoch 0.02. loss cost = 114.203598, 
5/20 batch done in 3.771s. at epoch 0.02. loss cost = 108.250908, 
5/20 batch done in 3.769s. at epoch 0.02. loss cost = 129.057404, 
5/20 batch done in 3.754s. at epoch 0.02. loss cost = 123.210297, 
6/20 batch done in 3.719s. at epoch 0.02. loss cost = 95.906021, 
8/20 batch done in 2.606s. at epoch 0.03. loss cost = 91.657524, 
6/20 batch done in 3.734s. at epoch 0.02. loss cost = 97.771301, 
6/20 batch done in 3.765s. at epoch 0.02. loss cost = 97.394386, 
6/20 batch done in 3.724s. at epoch 0.02. loss cost = 98.414803, 
6/20 batch done in 3.734s. at epoch 0.02. loss cost = 97.887939, 
6/20 batch done in 3.721s. at epoch 0.02. loss cost = 101.194313, 
6/20 batch done in 3.817s. at epoch 0.02. loss cost = 98.681648, 
6/20 batch done in 3.862s. at epoch 0.02. loss cost = 103.648331, 
6/20 batch done in 3.739s. at epoch 0.02. loss cost = 107.821487, 
6/20 batch done in 3.736s. at epoch 0.02. loss cost = 95.583679, 
6/20 batch done in 3.774s. at epoch 0.02. loss cost = 94.469406, 
6/20 batch done in 3.772s. at epoch 0.02. loss cost = 96.559464, 
6/20 batch done in 3.800s. at epoch 0.02. loss cost = 99.149635, 
6/20 batch done in 3.786s. at epoch 0.02. loss cost = 98.950882, 
9/20 batch done in 2.581s. at epoch 0.03. loss cost = 91.084496, 
7/20 batch done in 3.682s. at epoch 0.02. loss cost = 91.660484, 
7/20 batch done in 3.710s. at epoch 0.02. loss cost = 93.667465, 
7/20 batch done in 3.768s. at epoch 0.02. loss cost = 97.632240, 
7/20 batch done in 3.711s. at epoch 0.02. loss cost = 95.701248, 
7/20 batch done in 3.713s. at epoch 0.02. loss cost = 92.373085, 
7/20 batch done in 3.789s. at epoch 0.02. loss cost = 91.636703, 
7/20 batch done in 3.724s. at epoch 0.02. loss cost = 92.593964, 
7/20 batch done in 3.729s. at epoch 0.02. loss cost = 91.663849, 
7/20 batch done in 3.730s. at epoch 0.02. loss cost = 90.547119, 
7/20 batch done in 3.728s. at epoch 0.02. loss cost = 87.543045, 
7/20 batch done in 3.718s. at epoch 0.02. loss cost = 90.381401, 
7/20 batch done in 3.725s. at epoch 0.02. loss cost = 93.826019, 
10/20 batch done in 2.621s. at epoch 0.03. loss cost = 94.543213, 
7/20 batch done in 3.972s. at epoch 0.02. loss cost = 99.030556, 
7/20 batch done in 3.972s. at epoch 0.02. loss cost = 89.741257, 
8/20 batch done in 3.653s. at epoch 0.03. loss cost = 95.274429, 
8/20 batch done in 3.703s. at epoch 0.03. loss cost = 91.758644, 
8/20 batch done in 3.687s. at epoch 0.03. loss cost = 88.596924, 
11/20 batch done in 2.646s. at epoch 0.04. loss cost = 96.421715, 
8/20 batch done in 3.730s. at epoch 0.03. loss cost = 99.145889, 
8/20 batch done in 3.728s. at epoch 0.03. loss cost = 91.461861, 
8/20 batch done in 3.718s. at epoch 0.03. loss cost = 88.835106, 
8/20 batch done in 3.766s. at epoch 0.03. loss cost = 87.225029, 
8/20 batch done in 3.772s. at epoch 0.03. loss cost = 89.981041, 
8/20 batch done in 3.750s. at epoch 0.03. loss cost = 92.570251, 
8/20 batch done in 3.749s. at epoch 0.03. loss cost = 96.121368, 
8/20 batch done in 3.761s. at epoch 0.03. loss cost = 91.481537, 
8/20 batch done in 3.762s. at epoch 0.03. loss cost = 89.101982, 
8/20 batch done in 3.976s. at epoch 0.03. loss cost = 94.535095, 
8/20 batch done in 3.976s. at epoch 0.03. loss cost = 87.520164, 
12/20 batch done in 2.561s. at epoch 0.04. loss cost = 89.109787, 
9/20 batch done in 3.645s. at epoch 0.03. loss cost = 90.696663, 
9/20 batch done in 3.692s. at epoch 0.03. loss cost = 89.388535, 
9/20 batch done in 3.740s. at epoch 0.03. loss cost = 91.154007, 
9/20 batch done in 3.694s. at epoch 0.03. loss cost = 94.797256, 
9/20 batch done in 3.706s. at epoch 0.03. loss cost = 96.251022, 
9/20 batch done in 3.746s. at epoch 0.03. loss cost = 94.100510, 
9/20 batch done in 3.854s. at epoch 0.03. loss cost = 90.425339, 
9/20 batch done in 3.854s. at epoch 0.03. loss cost = 90.633087, 
9/20 batch done in 3.743s. at epoch 0.03. loss cost = 88.827477, 
9/20 batch done in 3.751s. at epoch 0.03. loss cost = 93.225700, 
9/20 batch done in 3.727s. at epoch 0.03. loss cost = 91.740074, 
9/20 batch done in 3.732s. at epoch 0.03. loss cost = 93.763992, 
13/20 batch done in 2.596s. at epoch 0.04. loss cost = 89.850739, 
9/20 batch done in 3.974s. at epoch 0.03. loss cost = 89.660248, 
9/20 batch done in 3.974s. at epoch 0.03. loss cost = 90.982925, 
10/20 batch done in 3.663s. at epoch 0.03. loss cost = 87.763214, 
10/20 batch done in 3.709s. at epoch 0.03. loss cost = 89.011719, 
10/20 batch done in 3.695s. at epoch 0.03. loss cost = 87.663010, 
10/20 batch done in 3.727s. at epoch 0.03. loss cost = 90.725006, 
10/20 batch done in 3.715s. at epoch 0.03. loss cost = 92.053818, 
10/20 batch done in 3.715s. at epoch 0.03. loss cost = 91.181015, 
14/20 batch done in 2.636s. at epoch 0.05. loss cost = 91.852951, 
10/20 batch done in 3.809s. at epoch 0.03. loss cost = 95.310219, 
10/20 batch done in 3.813s. at epoch 0.03. loss cost = 90.582130, 
10/20 batch done in 3.795s. at epoch 0.03. loss cost = 95.484093, 
10/20 batch done in 3.815s. at epoch 0.03. loss cost = 91.149231, 
10/20 batch done in 3.734s. at epoch 0.03. loss cost = 94.749756, 
10/20 batch done in 3.743s. at epoch 0.03. loss cost = 91.217316, 
10/20 batch done in 3.966s. at epoch 0.03. loss cost = 91.472969, 
10/20 batch done in 3.967s. at epoch 0.03. loss cost = 92.855888, 
11/20 batch done in 3.659s. at epoch 0.04. loss cost = 93.754562, 
15/20 batch done in 2.580s. at epoch 0.05. loss cost = 90.999084, 
11/20 batch done in 3.701s. at epoch 0.04. loss cost = 96.088303, 
11/20 batch done in 3.706s. at epoch 0.04. loss cost = 90.137032, 
11/20 batch done in 3.731s. at epoch 0.04. loss cost = 92.329735, 
11/20 batch done in 3.725s. at epoch 0.04. loss cost = 89.994629, 
11/20 batch done in 3.723s. at epoch 0.04. loss cost = 95.116539, 
11/20 batch done in 3.736s. at epoch 0.04. loss cost = 89.567329, 
11/20 batch done in 3.739s. at epoch 0.04. loss cost = 87.696632, 
11/20 batch done in 3.732s. at epoch 0.04. loss cost = 88.888168, 
11/20 batch done in 3.768s. at epoch 0.04. loss cost = 98.326462, 
11/20 batch done in 3.765s. at epoch 0.04. loss cost = 91.141342, 
11/20 batch done in 3.771s. at epoch 0.04. loss cost = 95.026245, 
16/20 batch done in 2.580s. at epoch 0.05. loss cost = 91.511230, 
11/20 batch done in 3.954s. at epoch 0.04. loss cost = 86.772217, 
11/20 batch done in 3.955s. at epoch 0.04. loss cost = 90.559631, 
12/20 batch done in 3.660s. at epoch 0.04. loss cost = 92.559006, 
12/20 batch done in 3.704s. at epoch 0.04. loss cost = 83.674828, 
12/20 batch done in 3.675s. at epoch 0.04. loss cost = 91.350708, 
12/20 batch done in 3.714s. at epoch 0.04. loss cost = 88.600609, 
12/20 batch done in 3.725s. at epoch 0.04. loss cost = 93.597618, 
12/20 batch done in 3.706s. at epoch 0.04. loss cost = 92.234573, 
12/20 batch done in 3.720s. at epoch 0.04. loss cost = 91.470810, 
12/20 batch done in 3.737s. at epoch 0.04. loss cost = 90.787140, 
17/20 batch done in 2.623s. at epoch 0.06. loss cost = 95.278511, 
12/20 batch done in 3.760s. at epoch 0.04. loss cost = 91.423050, 
12/20 batch done in 3.800s. at epoch 0.04. loss cost = 88.432068, 
12/20 batch done in 3.751s. at epoch 0.04. loss cost = 87.950027, 
12/20 batch done in 3.755s. at epoch 0.04. loss cost = 91.026306, 
12/20 batch done in 3.950s. at epoch 0.04. loss cost = 92.570290, 
12/20 batch done in 3.952s. at epoch 0.04. loss cost = 92.553856, 
13/20 batch done in 3.657s. at epoch 0.04. loss cost = 91.905899, 
13/20 batch done in 3.708s. at epoch 0.04. loss cost = 94.612793, 
18/20 batch done in 2.592s. at epoch 0.06. loss cost = 98.220116, 
13/20 batch done in 3.663s. at epoch 0.04. loss cost = 88.498924, 
13/20 batch done in 3.704s. at epoch 0.04. loss cost = 90.227890, 
13/20 batch done in 3.708s. at epoch 0.04. loss cost = 94.267471, 
13/20 batch done in 3.698s. at epoch 0.04. loss cost = 91.179146, 
13/20 batch done in 3.710s. at epoch 0.04. loss cost = 95.834084, 
13/20 batch done in 3.712s. at epoch 0.04. loss cost = 91.148163, 
13/20 batch done in 3.709s. at epoch 0.04. loss cost = 90.624786, 
13/20 batch done in 3.750s. at epoch 0.04. loss cost = 94.205223, 
13/20 batch done in 3.723s. at epoch 0.04. loss cost = 95.646751, 
13/20 batch done in 3.734s. at epoch 0.04. loss cost = 90.526871, 
19/20 batch done in 2.580s. at epoch 0.06. loss cost = 90.151375, 
13/20 batch done in 3.981s. at epoch 0.04. loss cost = 97.469002, 
13/20 batch done in 3.981s. at epoch 0.04. loss cost = 90.780991, 
14/20 batch done in 3.648s. at epoch 0.05. loss cost = 95.960236, 
14/20 batch done in 3.680s. at epoch 0.05. loss cost = 90.058220, 
14/20 batch done in 3.684s. at epoch 0.05. loss cost = 89.017220, 
14/20 batch done in 3.659s. at epoch 0.05. loss cost = 91.566010, 
14/20 batch done in 3.659s. at epoch 0.05. loss cost = 92.215080, 
14/20 batch done in 3.706s. at epoch 0.05. loss cost = 93.611305, 
14/20 batch done in 3.771s. at epoch 0.05. loss cost = 92.990807, 
14/20 batch done in 3.760s. at epoch 0.05. loss cost = 94.589302, 
14/20 batch done in 3.744s. at epoch 0.05. loss cost = 86.682663, 
14/20 batch done in 3.740s. at epoch 0.05. loss cost = 95.061684, 
14/20 batch done in 3.772s. at epoch 0.05. loss cost = 89.001694, 
14/20 batch done in 3.737s. at epoch 0.05. loss cost = 89.474075, 
15/20 batch done in 3.639s. at epoch 0.05. loss cost = 92.400650, 
14/20 batch done in 3.979s. at epoch 0.05. loss cost = 86.229195, 
14/20 batch done in 3.979s. at epoch 0.05. loss cost = 93.080925, 
15/20 batch done in 3.672s. at epoch 0.05. loss cost = 90.931648, 
15/20 batch done in 3.619s. at epoch 0.05. loss cost = 90.807396, 
15/20 batch done in 3.649s. at epoch 0.05. loss cost = 92.646774, 
15/20 batch done in 3.645s. at epoch 0.05. loss cost = 92.198906, 
15/20 batch done in 3.646s. at epoch 0.05. loss cost = 89.534966, 
15/20 batch done in 3.715s. at epoch 0.05. loss cost = 93.522934, 
15/20 batch done in 3.725s. at epoch 0.05. loss cost = 94.138229, 
15/20 batch done in 3.703s. at epoch 0.05. loss cost = 98.045448, 
15/20 batch done in 3.730s. at epoch 0.05. loss cost = 93.146538, 
15/20 batch done in 3.741s. at epoch 0.05. loss cost = 90.204353, 
15/20 batch done in 3.742s. at epoch 0.05. loss cost = 87.343781, 
16/20 batch done in 3.595s. at epoch 0.05. loss cost = 94.524849, 
16/20 batch done in 3.607s. at epoch 0.05. loss cost = 95.315903, 
15/20 batch done in 3.963s. at epoch 0.05. loss cost = 91.596039, 
15/20 batch done in 3.963s. at epoch 0.05. loss cost = 92.508652, 
16/20 batch done in 3.605s. at epoch 0.05. loss cost = 90.406914, 
16/20 batch done in 3.652s. at epoch 0.05. loss cost = 92.603806, 
16/20 batch done in 3.654s. at epoch 0.05. loss cost = 95.711868, 
16/20 batch done in 3.638s. at epoch 0.05. loss cost = 96.462982, 
16/20 batch done in 3.715s. at epoch 0.05. loss cost = 90.719490, 
16/20 batch done in 3.713s. at epoch 0.05. loss cost = 93.447731, 
16/20 batch done in 3.709s. at epoch 0.05. loss cost = 100.770630, 
16/20 batch done in 3.717s. at epoch 0.05. loss cost = 87.833664, 
16/20 batch done in 3.745s. at epoch 0.05. loss cost = 86.242912, 
16/20 batch done in 3.740s. at epoch 0.05. loss cost = 93.445183, 
17/20 batch done in 3.618s. at epoch 0.06. loss cost = 94.590500, 
17/20 batch done in 3.627s. at epoch 0.06. loss cost = 95.774071, 
17/20 batch done in 3.604s. at epoch 0.06. loss cost = 92.399529, 
16/20 batch done in 3.946s. at epoch 0.05. loss cost = 95.187958, 
16/20 batch done in 3.947s. at epoch 0.05. loss cost = 93.808411, 
17/20 batch done in 3.661s. at epoch 0.06. loss cost = 90.608673, 
17/20 batch done in 3.660s. at epoch 0.06. loss cost = 88.379372, 
17/20 batch done in 3.639s. at epoch 0.06. loss cost = 88.870728, 
17/20 batch done in 3.713s. at epoch 0.06. loss cost = 92.623672, 
17/20 batch done in 3.721s. at epoch 0.06. loss cost = 93.820702, 
17/20 batch done in 3.703s. at epoch 0.06. loss cost = 85.639450, 
17/20 batch done in 3.723s. at epoch 0.06. loss cost = 90.246651, 
17/20 batch done in 3.741s. at epoch 0.06. loss cost = 85.081772, 
17/20 batch done in 3.741s. at epoch 0.06. loss cost = 90.009224, 
18/20 batch done in 3.600s. at epoch 0.06. loss cost = 86.934937, 
18/20 batch done in 3.609s. at epoch 0.06. loss cost = 92.350807, 
18/20 batch done in 3.600s. at epoch 0.06. loss cost = 90.142693, 
18/20 batch done in 3.646s. at epoch 0.06. loss cost = 87.610413, 
18/20 batch done in 3.647s. at epoch 0.06. loss cost = 94.629494, 
18/20 batch done in 3.639s. at epoch 0.06. loss cost = 88.592323, 
17/20 batch done in 3.951s. at epoch 0.06. loss cost = 89.881599, 
17/20 batch done in 3.950s. at epoch 0.06. loss cost = 92.281548, 
18/20 batch done in 3.729s. at epoch 0.06. loss cost = 95.423508, 
18/20 batch done in 3.731s. at epoch 0.06. loss cost = 94.797470, 
18/20 batch done in 3.755s. at epoch 0.06. loss cost = 86.054810, 
18/20 batch done in 3.718s. at epoch 0.06. loss cost = 94.850273, 
18/20 batch done in 3.786s. at epoch 0.06. loss cost = 88.078773, 
18/20 batch done in 3.756s. at epoch 0.06. loss cost = 90.273804, 
19/20 batch done in 3.675s. at epoch 0.06. loss cost = 95.912582, 
19/20 batch done in 3.640s. at epoch 0.06. loss cost = 92.587662, 
19/20 batch done in 3.615s. at epoch 0.06. loss cost = 91.914268, 
19/20 batch done in 3.663s. at epoch 0.06. loss cost = 94.622749, 
19/20 batch done in 3.659s. at epoch 0.06. loss cost = 92.776932, 
19/20 batch done in 3.619s. at epoch 0.06. loss cost = 93.470703, 
18/20 batch done in 3.961s. at epoch 0.06. loss cost = 93.812935, 
18/20 batch done in 3.961s. at epoch 0.06. loss cost = 94.292717, 
19/20 batch done in 3.758s. at epoch 0.06. loss cost = 95.717484, 
19/20 batch done in 3.731s. at epoch 0.06. loss cost = 92.796021, 
19/20 batch done in 3.705s. at epoch 0.06. loss cost = 91.870674, 
19/20 batch done in 3.721s. at epoch 0.06. loss cost = 96.193649, 
19/20 batch done in 3.718s. at epoch 0.06. loss cost = 87.553780, 
19/20 batch done in 3.712s. at epoch 0.06. loss cost = 93.856224, 
19/20 batch done in 3.613s. at epoch 0.06. loss cost = 98.444229, 
19/20 batch done in 3.613s. at epoch 0.06. loss cost = 91.678665, 
Application 52491713 exit codes: 1
Application 52491713 resources: utime ~1195s, stime ~80s, Rss ~472244, inblocks ~2349740, outblocks ~167586
