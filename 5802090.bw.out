----------------------------------------
Begin Torque Prologue on nid27562
at Sat Nov 26 19:23:53 CST 2016
Job Id:			5802090.bw
Username:		tra245
Group:			TRAIN_bacu
Job name:		neruraltalk_16cores
Requested resources:	neednodes=1:ppn=16:xk,nodes=1:ppn=16:xk,walltime=40:00:00
Queue:			normal
Account:		bacu
End Torque Prologue:  0.078 elapsed
----------------------------------------




parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
parsed parameters:
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
parsed parameters:
}
{
  "grad_clip": 5, 
  "rnn_relu_encoders": 0, 
  "dataset": "flickr8k", 
  "image_encoding_size": 256, 
  "eval_max_images": -1, 
  "drop_prob_decoder": 0.5, 
  "word_encoding_size": 256, 
  "max_epochs": 50, 
  "eval_batch_size": 100, 
  "fappend": "baseline", 
  "generator": "lstm", 
  "min_ppl_or_abort": -1, 
  "tanhC_version": 0, 
  "write_checkpoint_ppl_threshold": -1, 
  "decay_rate": 0.999, 
  "rnn_feed_once": 0, 
  "hidden_size": 256, 
  "momentum": 0.0, 
  "worker_status_output_directory": "status/", 
  "init_model_from": "", 
  "learning_rate": 0.001, 
  "checkpoint_output_directory": "cv/", 
  "do_grad_check": 0, 
  "word_count_threshold": 5, 
  "batch_size": 100, 
  "regc": 1e-08, 
  "smooth_eps": 1e-08, 
  "solver": "rmsprop", 
  "eval_period": 1.0, 
  "drop_prob_encoder": 0.5
}
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
Initializing data provider for dataset flickr8k...
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/dataset.json
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
BasicDataProvider: reading data/flickr8k/vgg_feats.mat
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
preprocessing word counts and creating vocab based on word count threshold 5
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.34s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
filtered words from 7374 to 2537 in 0.35s
0/15000 batch done in 5.685s. at epoch 0.00. loss cost = 298.511078, 
1/15000 batch done in 0.270s. at epoch 0.00. loss cost = 280.385315, 
2/15000 batch done in 0.266s. at epoch 0.01. loss cost = 254.055466, 
3/15000 batch done in 0.267s. at epoch 0.01. loss cost = 219.217148, 
4/15000 batch done in 0.269s. at epoch 0.01. loss cost = 182.258087, 
5/15000 batch done in 0.266s. at epoch 0.02. loss cost = 138.131683, 
6/15000 batch done in 0.267s. at epoch 0.02. loss cost = 103.010529, 
7/15000 batch done in 0.266s. at epoch 0.02. loss cost = 99.276497, 
8/15000 batch done in 0.267s. at epoch 0.03. loss cost = 87.583023, 
9/15000 batch done in 0.267s. at epoch 0.03. loss cost = 88.768410, 
10/15000 batch done in 0.266s. at epoch 0.03. loss cost = 93.733055, 
11/15000 batch done in 0.267s. at epoch 0.04. loss cost = 91.483025, 
12/15000 batch done in 0.266s. at epoch 0.04. loss cost = 89.320038, 
13/15000 batch done in 0.267s. at epoch 0.04. loss cost = 86.873749, 
14/15000 batch done in 0.266s. at epoch 0.05. loss cost = 90.448326, 
15/15000 batch done in 0.266s. at epoch 0.05. loss cost = 89.413033, 
16/15000 batch done in 0.268s. at epoch 0.05. loss cost = 93.695580, 
17/15000 batch done in 0.266s. at epoch 0.06. loss cost = 94.228882, 
18/15000 batch done in 0.359s. at epoch 0.06. loss cost = 90.187119, 
19/15000 batch done in 0.267s. at epoch 0.06. loss cost = 88.741539, 
20/15000 batch done in 0.267s. at epoch 0.07. loss cost = 92.639763, 
21/15000 batch done in 0.267s. at epoch 0.07. loss cost = 87.005051, 
22/15000 batch done in 0.266s. at epoch 0.07. loss cost = 92.038551, 
23/15000 batch done in 0.267s. at epoch 0.08. loss cost = 88.139938, 
24/15000 batch done in 0.268s. at epoch 0.08. loss cost = 89.528976, 
25/15000 batch done in 0.266s. at epoch 0.08. loss cost = 95.579063, 
26/15000 batch done in 0.268s. at epoch 0.09. loss cost = 91.109207, 
27/15000 batch done in 0.266s. at epoch 0.09. loss cost = 88.013214, 
28/15000 batch done in 0.267s. at epoch 0.09. loss cost = 92.821159, 
29/15000 batch done in 0.266s. at epoch 0.10. loss cost = 94.613869, 
30/15000 batch done in 0.266s. at epoch 0.10. loss cost = 86.923508, 
31/15000 batch done in 0.268s. at epoch 0.10. loss cost = 95.961220, 
32/15000 batch done in 0.266s. at epoch 0.11. loss cost = 86.987755, 
33/15000 batch done in 0.267s. at epoch 0.11. loss cost = 94.643524, 
34/15000 batch done in 0.266s. at epoch 0.11. loss cost = 90.280197, 
35/15000 batch done in 0.267s. at epoch 0.12. loss cost = 91.817589, 
36/15000 batch done in 0.267s. at epoch 0.12. loss cost = 85.718208, 
37/15000 batch done in 0.266s. at epoch 0.12. loss cost = 89.644043, 
38/15000 batch done in 0.360s. at epoch 0.13. loss cost = 91.580864, 
39/15000 batch done in 0.266s. at epoch 0.13. loss cost = 88.779762, 
40/15000 batch done in 0.267s. at epoch 0.13. loss cost = 88.291328, 
41/15000 batch done in 0.267s. at epoch 0.14. loss cost = 87.297028, 
42/15000 batch done in 0.266s. at epoch 0.14. loss cost = 88.392998, 
43/15000 batch done in 0.267s. at epoch 0.14. loss cost = 89.543587, 
44/15000 batch done in 0.266s. at epoch 0.15. loss cost = 98.801651, 
45/15000 batch done in 0.266s. at epoch 0.15. loss cost = 90.258720, 
46/15000 batch done in 0.267s. at epoch 0.15. loss cost = 85.612602, 
47/15000 batch done in 0.266s. at epoch 0.16. loss cost = 90.832504, 
48/15000 batch done in 0.267s. at epoch 0.16. loss cost = 86.839775, 
49/15000 batch done in 0.266s. at epoch 0.16. loss cost = 87.565613, 
50/15000 batch done in 0.266s. at epoch 0.17. loss cost = 91.101860, 
51/15000 batch done in 0.267s. at epoch 0.17. loss cost = 88.680046, 
52/15000 batch done in 0.266s. at epoch 0.17. loss cost = 92.326775, 
53/15000 batch done in 0.267s. at epoch 0.18. loss cost = 89.082314, 
54/15000 batch done in 0.266s. at epoch 0.18. loss cost = 85.859467, 
Application 53336930 exit codes: 1
Application 53336930 resources: utime ~83s, stime ~77s, Rss ~572012, inblocks ~2366516, outblocks ~4182
